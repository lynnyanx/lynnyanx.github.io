# üîç AI Vision Inspector

<p align="center">
  <img src="docs/images/logo.png" alt="AI Vision Inspector Logo" width="200"/>
</p>

<p align="center">
  <strong>Deep Learning-Based Industrial Vision Inspection Platform</strong>
</p>

<p align="center">
  <a href="#-features">Features</a> ‚Ä¢
  <a href="#-architecture">Architecture</a> ‚Ä¢
  <a href="#-getting-started">Getting Started</a> ‚Ä¢
  <a href="#-project-structure">Project Structure</a> ‚Ä¢
  <a href="#-roadmap">Roadmap</a>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/.NET-8.0-512BD4?style=flat-square&logo=dotnet" alt=".NET 8"/>
  <img src="https://img.shields.io/badge/WPF-Modern_UI-0078D4?style=flat-square&logo=windows" alt="WPF"/>
  <img src="https://img.shields.io/badge/ONNX_Runtime-GPU-76B900?style=flat-square&logo=nvidia" alt="ONNX Runtime GPU"/>
  <img src="https://img.shields.io/badge/PyTorch-2.0+-EE4C2C?style=flat-square&logo=pytorch" alt="PyTorch"/>
  <img src="https://img.shields.io/badge/License-MIT-green?style=flat-square" alt="License"/>
</p>

---

## üìñ Overview

**AI Vision Inspector** is a full-stack AI vision inspection software designed for industrial manufacturing scenarios. It integrates **data management**, **model training**, **real-time inference**, **camera acquisition**, and **incremental learning** into a complete workflow.

This project addresses the pain points of traditional industrial vision inspection systems:
- ‚ùå Traditional approach: Requires specialized algorithm engineers, complex environment setup, expensive commercial software licenses
- ‚úÖ This solution: **No-code training**, **one-click deployment**, **on-site adaptive learning**

### üéØ Use Cases

| Scenario | Description | Algorithm |
|----------|-------------|-----------|
| **Defect Detection** | Surface scratches, stains, cracks, missing parts | PatchCore / STFPM |
| **Product Classification** | Model identification, OK/NG sorting | ResNet / MobileNet |
| **Object Counting** | Part counting, assembly completeness check | YOLOv8 / YOLOv11 |

---

## ‚ú® Features

### üß† AI Inference Engine
- **Multi-task Support**: Anomaly detection, image classification, object detection
- **GPU Acceleration**: ONNX Runtime + CUDA, inference latency < 50ms
- **Heatmap Visualization**: Intuitive display of anomaly region localization
- **Adaptive Thresholds**: Strict / Balanced / Loose three-tier automatic threshold recommendation

### üì∑ Camera Acquisition System
- **Multi-brand Support**: Hikvision (MVS SDK), Daheng, Basler (reserved interfaces)
- **Real-time Preview**: 30+ FPS continuous acquisition
- **Parameter Control**: Real-time adjustment of exposure, gain, gamma
- **Auto Inference**: Capture-and-detect, seamless AI pipeline integration

### üéì Model Training Pipeline
- **No-code Training**: GUI-based configuration, one-click training start
- **Real-time Monitoring**: Training progress, loss curves, log streaming
- **Auto Deployment**: Automatic ONNX export and system registration upon completion
- **Training History**: Complete records of training parameters and metrics


### üîÑ Incremental Learning System
- **On-site Feedback**: One-click labeling of misdetected samples (OK/NG)
- **Smart Updates**: Automatic model fine-tuning based on feedback samples
- **Version Management**: Automatic backup of historical versions, one-click rollback support
- **Auto Validation**: Post-update automatic validation, auto-rollback on performance degradation

### üìä Data Management
- **Dataset Wizard**: Visual creation of MVTec / ImageFolder / YOLO format datasets
- **Batch Import**: Drag-and-drop import with automatic filename normalization
- **Statistics Dashboard**: Real-time statistics, trend charts, yield analysis

### üîê Enterprise Features
- **Permission Management**: Admin / Operator two-level permissions
- **Configuration Backup**: One-click export/import of all configurations
- **History Tracing**: Automatic archiving of detection results, date-based queries

---

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        Presentation Layer                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ MainWindow  ‚îÇ  ‚îÇ  Dialogs    ‚îÇ  ‚îÇ   StatisticsDashboard   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ (AvalonDock)‚îÇ  ‚îÇ (MahApps)   ‚îÇ  ‚îÇ   (LiveCharts)          ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                        ViewModel Layer (MVVM)                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇMainViewModel‚îÇ  ‚îÇInferenceVM  ‚îÇ  ‚îÇ LearningControlVM       ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                        Service Layer                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ OnnxAnomalyRunner‚îÇ  ‚îÇ CameraManager    ‚îÇ  ‚îÇ AuthService   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ OnnxClassRunner  ‚îÇ  ‚îÇ ImageSourceMgr   ‚îÇ  ‚îÇ ConfigBackup  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ OnnxYoloRunner   ‚îÇ  ‚îÇ HikvisionProvider‚îÇ  ‚îÇ Statistics    ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ              Incremental Learning Module                  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  SampleManager ‚îÇ VersionManager ‚îÇ ValidationService      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  RollbackMgr   ‚îÇ LearningStrategy (PatchCore/STFPM/CNN)  ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                        Infrastructure                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇONNX Runtime ‚îÇ  ‚îÇ MVS SDK     ‚îÇ  ‚îÇ Python Interop          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   (GPU)     ‚îÇ  ‚îÇ (Hikvision) ‚îÇ  ‚îÇ (PyTorch Training)      ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Tech Stack

| Layer | Technology | Description |
|-------|------------|-------------|
| **Frontend Framework** | WPF + .NET 8 | Modern desktop application |
| **UI Components** | MahApps.Metro + AvalonDock | VS2022-style theme |
| **Charting Library** | LiveChartsCore | Real-time data visualization |
| **Inference Engine** | ONNX Runtime GPU | CUDA-accelerated inference |
| **Training Framework** | PyTorch + Anomalib | Anomaly detection algorithm library |
| **Camera SDK** | Hikvision MVS SDK | Industrial camera acquisition |
| **Configuration** | YamlDotNet | YAML format configuration |

---

## üöÄ Getting Started

### Requirements

- **Operating System**: Windows 10/11 64-bit
- **Runtime**: .NET 8.0 Runtime
- **GPU (Optional)**: NVIDIA GPU + CUDA 11.x (for accelerated inference and training)
- **Python (Training)**: Python 3.10+ or Anaconda

### Installation

```bash
# 1. Clone the repository
git clone https://github.com/yourusername/ai-vision-inspector.git
cd ai-vision-inspector

# 2. Install Python dependencies (for training features)
pip install -r scripts/requirements.txt

# 3. Build and run
dotnet build WpfAnomalyMvp.sln
dotnet run --project WpfAnomalyMvp
```

### Default Login

- **Username**: `admin`
- **Password**: `admin123`

---

## üìÅ Project Structure

```
ai-vision-inspector/
‚îú‚îÄ‚îÄ WpfAnomalyMvp/              # Main application project
‚îÇ   ‚îú‚îÄ‚îÄ Views/                  # XAML views
‚îÇ   ‚îú‚îÄ‚îÄ ViewModels/             # MVVM view models
‚îÇ   ‚îú‚îÄ‚îÄ Services/               # Business service layer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ IncrementalLearning/  # Incremental learning module
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Interfaces/         # Service interface definitions
‚îÇ   ‚îú‚îÄ‚îÄ Models/                 # Data models
‚îÇ   ‚îî‚îÄ‚îÄ Themes/                 # UI theme styles
‚îú‚îÄ‚îÄ WpfAnomalyMvp.Tests/        # Unit test project
‚îú‚îÄ‚îÄ scripts/                    # Python training scripts
‚îÇ   ‚îú‚îÄ‚îÄ train_anomaly.py        # Anomaly detection training
‚îÇ   ‚îú‚îÄ‚îÄ train_classifier.py     # Classification model training
‚îÇ   ‚îî‚îÄ‚îÄ finetune_*.py           # Incremental learning scripts
‚îú‚îÄ‚îÄ configs/                    # Configuration files
‚îÇ   ‚îú‚îÄ‚îÄ registry.yaml           # Model registry
‚îÇ   ‚îî‚îÄ‚îÄ thresholds.yaml         # Threshold configuration
‚îú‚îÄ‚îÄ models/                     # ONNX model files
‚îî‚îÄ‚îÄ data/                       # Dataset directory
```

---

## üìä Performance Metrics

| Metric | Value | Test Environment |
|--------|-------|------------------|
| **Inference Latency (GPU)** | 15-30 ms | RTX 3060, 224√ó224 |
| **Inference Latency (CPU)** | 80-150 ms | i7-12700 |
| **Camera Capture FPS** | 30+ FPS | Hikvision MV-CS050-10GC |
| **Training Speed** | ~2 min/epoch | RTX 3060, 100 images |
| **Memory Usage** | 500-800 MB | Single model loaded |

---

## üó∫Ô∏è Roadmap

### ‚úÖ Completed

- [x] Core inference engine (PatchCore/STFPM/YOLO)
- [x] Camera acquisition system (Hikvision)
- [x] Model training pipeline
- [x] Incremental learning system
- [x] Statistics dashboard
- [x] Permission management system
- [x] Configuration backup/restore

### üöß In Progress

- [ ] Adaptive threshold learning
- [ ] Daheng/Basler camera adapters

### üìã Planned

- [ ] OCR character recognition
- [ ] Web remote monitoring
- [ ] Industrial protocol support (Modbus/OPC UA)
- [ ] Multi-camera synchronization

---

## üõ†Ô∏è Key Design Patterns

### MVVM Architecture
Separation of views and business logic for better testability and maintainability.

### Strategy Pattern
Extensible learning strategies for different model types (PatchCore, STFPM, Classification).

### Interface Abstraction
`IImageSource` and `ICameraProvider` interfaces enable easy extension for new camera brands.

### Service Locator
Centralized service registration and resolution for dependency management.

---

## ü§ù Contributing

Contributions are welcome! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## üìß Contact

- **Author**: [Your Name]
- **Email**: [your.email@example.com]
- **LinkedIn**: [Your LinkedIn Profile]

---

<p align="center">
  <sub>Built with ‚ù§Ô∏è for Industrial AI Vision</sub>
</p>
